{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import os, cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import random, tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import mobilenet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aada30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from Kaggle example code:\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"\n",
    "    Plot images in one row\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n_images, idx + 1)\n",
    "        # plt.xticks([]); \n",
    "        # plt.yticks([])\n",
    "        # get title from the parameter names\n",
    "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
    "        \n",
    "        if type(image) == str:\n",
    "            image = mpimg.imread(image)\n",
    "        \n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create path to data\n",
    "\n",
    "# Gianluca's Path:\n",
    "#path = \"/data\"\n",
    "\n",
    "## Johnathan's Path:\n",
    "# path = \"/content/drive/MyDrive/Grad School/Penn_MUSA/Spring2022/650_RemoteSensing/LULC_FinalProject/data\"\n",
    "## Local path\n",
    "path = os.getcwd()\n",
    "\n",
    "\n",
    "## Define path to the data\n",
    "data_path = \"{}\".format(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classes and their respective pixel values\n",
    "class_dict = pd.read_csv('{}/class_dict.csv'.format(path))\n",
    "class_names = class_dict['name'].values.tolist()\n",
    "class_rgb_vals = class_dict[['r', 'g', 'b']].values.tolist()\n",
    "\n",
    "# Useful to shortlist specific classes in datasets with large number of classes\n",
    "select_classes = class_names\n",
    "\n",
    "# Get RGB values of required classes\n",
    "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
    "select_class_rgb_values =  np.array(class_rgb_vals)[select_class_indices]\n",
    "\n",
    "print('Selected classes and their corresponding RGB values in labels:')\n",
    "print('Class Names: ', class_names)\n",
    "print('Class RGB values: ', class_rgb_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata file - contains relative paths for images and masks\n",
    "metadata = pd.read_csv('{}/metadata.csv'.format(path))\n",
    "\n",
    "# Preparing metadata for use\n",
    "metadata = metadata[metadata['split']=='train'] # Filter out images that do not have masks (those images are part of the challenge set)\n",
    "metadata = metadata[['image_id', 'sat_image_path', 'mask_path']] # Remove the image status column\n",
    "\n",
    "# set paths to absolute paths rather than relative paths:\n",
    "metadata['sat_image_path'] = metadata['sat_image_path'].apply(lambda img_pth: os.path.join(path, img_pth))\n",
    "metadata['mask_path'] = metadata['mask_path'].apply(lambda img_pth: os.path.join(path, img_pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.sort_values('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585baa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_Loc = metadata['sat_image_path'][245]\n",
    "mask_Loc = metadata['mask_path'][245]\n",
    "visualize(Image = (np.asarray(PIL.Image.open(img_Loc))/255), Mask = mask_Loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(mask_Loc)\n",
    "uni, freq = np.unique(np.asarray(img), return_counts=True)\n",
    "\n",
    "print('Unique Vals: {}'.format(uni))\n",
    "print('Freq of vals: {}'.format(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentify the number of satellite images and corresponding masks\n",
    "numSatImg = len(metadata['sat_image_path'])\n",
    "numMask = len(metadata['mask_path'])\n",
    "print(\"Number of original satellite images: \" + str(numSatImg))\n",
    "print(\"Number of original masks: \" + str(numMask))\n",
    "\n",
    "# Open example image\n",
    "img = PIL.Image.open(metadata['sat_image_path'][0])\n",
    "# Get dimensionality of that image\n",
    "numPixels = np.asarray(img).shape\n",
    "print('Number of pixels in each image: {}'.format(numPixels))\n",
    "\n",
    "# Initialize arrays for cropped sat images and masks\n",
    "# First we will need to trim the 2448 x 2448 image to 2048 x 2048 image so that it can be used with U-net \n",
    "# which needs to have images with sizes divisible by 32\n",
    "# We will then crop each image down to sections of 128 x 128 x 3, which produces 16 cropped images per original sat image.\n",
    "# If you want to change the size of the cropped image, change the denominator for cropimg width / height below\n",
    "cropImg_height = int((numPixels[0]-400) / 16) # 2048 / 16 = 128\n",
    "cropImg_width = int((numPixels[1]-400) / 16) # 2048 / 16 = 128\n",
    "\n",
    "\n",
    "X = np.zeros([(numSatImg * 256), cropImg_height, cropImg_width, numPixels[2]], dtype='uint8')\n",
    "y = np.zeros([(numMask * 256), cropImg_height, cropImg_width, numPixels[2]], dtype='uint8')\n",
    "print('Shape of cropped sat image dataset: {}'.format(X.shape))\n",
    "print('Shape of cropped mask dataset: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b43040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract paths from pandas df to np array for iteration purposes - don't want to use iterrows b/c its slow!\n",
    "Xrows = np.asarray(metadata['sat_image_path'])\n",
    "yrows = np.asarray(metadata['mask_path'])\n",
    "\n",
    "\n",
    "# Step 0: Trim images from 2448x2448 to 2048x24048 to make the image size divisible by 32 for Unet purposes\n",
    "# Step 1: Iterate through image & corresponding mask paths and read images into memory\n",
    "# Step 2: iterate through original img matrix and crop to predefined crop height & width\n",
    "# Step 3: Save cropped matrix to working dataset\n",
    "\n",
    "cropImgIdx = 0\n",
    "\n",
    "for i in range(0, len(Xrows)):\n",
    "  img = np.asarray(cv2.imread(Xrows[i]))\n",
    "  mask = np.asarray(cv2.imread(yrows[i]))\n",
    "  \n",
    "  # Trim image to [2048,2048,3] by trimming extra 200px off from the border\n",
    "  img = np.array(img[200:2248, 200:2248, :])\n",
    "\n",
    "  # Iterate through each row\n",
    "  for r in range(0, img.shape[0], cropImg_height):\n",
    "    # Iterate through each column\n",
    "    for c in range(0, img.shape[1], cropImg_width):\n",
    "\n",
    "      # Slice mask by cropping window first\n",
    "      # That way we can check if if we're going to use the image or not\n",
    "      newMask = np.array(mask[r:r+cropImg_height, c:c+cropImg_width, :])\n",
    "      newMask = cv2.cvtColor(newMask, cv2.COLOR_BGR2RGB)\n",
    "      \n",
    "      # Convert mask to grayscale to find distribution of classes\n",
    "      grayMask = cv2.cvtColor(newMask, cv2.COLOR_BGR2GRAY)\n",
    "      # Get frequency of each classification in the cropped mask\n",
    "      unique, frequency = np.unique(grayMask, return_counts= True)\n",
    "      frequency = frequency / (len(grayMask.flatten()))\n",
    "\n",
    "      # Check if any classes are represent 99% of image\n",
    "      # If that is the case, throw it out\n",
    "      if (frequency >= 0.99).any():\n",
    "        continue\n",
    "\n",
    "      # Crop image if we make it past the majority class checker\n",
    "      newImg = np.array(img[r:r+cropImg_height, c:c+cropImg_width, :])\n",
    "      newImg = cv2.cvtColor(newImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      X[cropImgIdx,:] = newImg\n",
    "      y[cropImgIdx,:] = newMask\n",
    "\n",
    "      cropImgIdx += 1\n",
    "\n",
    "print('There were {} images cropped from {} original images'.format((cropImgIdx-1), numSatImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31274eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropImgIdx -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:cropImgIdx, :,:,:]\n",
    "y = y[0:cropImgIdx, :,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dbac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58538516",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogImg = Xrows[0]\n",
    "ogmask = yrows[0]\n",
    "cropImg = X[0]\n",
    "cropMsk = y[0]\n",
    "\n",
    "visualize(original_Image = ogImg, original_Mask = ogmask)\n",
    "visualize(crop_Image = cropImg, crop_Mask = cropMsk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c03923",
   "metadata": {},
   "source": [
    "# U-Net model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ee709",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-unet\n",
    "\n",
    "from keras_unet.models import vanilla_unet, custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle DataFrame\n",
    "## For function origin, check this stack overflow: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def unison_shuffled(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "X_shuf, y_shuf = unison_shuffled(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample so that we don't break our computers\n",
    "X_down = X_shuf[0:1000, :,:,:]\n",
    "y_down = y_shuf[0:1000, :,:,:]\n",
    "print(X_down.shape)\n",
    "print(y_down.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6823efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_down.max(), y_down.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28995b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_down.shape, y_down.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(X_down, dtype=np.float32)/255\n",
    "y = np.asarray(y_down, dtype=np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbffdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.max(), y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train = to_categorical(mask_train, 4)\n",
    "mask_train = mask_train.reshape((634,64,64,4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_train: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.models import custom_unet\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "\n",
    "model = custom_unet(\n",
    "    input_shape,\n",
    "    use_batch_norm=False,\n",
    "    num_classes=7,\n",
    "    filters=64,\n",
    "    dropout=0.2,\n",
    "    output_activation='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a18fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ca6b9",
   "metadata": {},
   "source": [
    "# Compile + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_filename = 'segm_model_v0.h5'\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(), \n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    #loss='binary_crossentropy',\n",
    "    loss=jaccard_distance,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 50, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc79d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
